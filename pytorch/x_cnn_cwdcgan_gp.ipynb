{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, autograd, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "num_epochs = 30\n",
    "\n",
    "z_dimension = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "#     transforms.Resize(64),\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "#     transforms.Normalize((0.1307,), (0.3081,))\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST('~/data/mnist', transform=img_transform) # , download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_init(m, mean, std):\n",
    "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
    "        m.weight.data.normal_(mean, std)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    alpha = torch.rand(1, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    alpha = alpha.to(device)\n",
    "    \n",
    "    interpolates = alpha * real_data.detach() + ((1 - alpha) * fake_data.detach())\n",
    "\n",
    "    interpolates = interpolates.to(device)\n",
    "    interpolates.requires_grad_(True)\n",
    "\n",
    "    disc_interpolates, _ = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradients = gradients.view(gradients.size(0), -1)                              \n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise_label(batch_size):\n",
    "    label = np.random.randint(0, 10, batch_size)\n",
    "    #prefix = np.zeros((batch_size, 10))\n",
    "    #prefix[:, label] = 1\n",
    "    return label # prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, label):\n",
    "    prefix = np.zeros((batch_size, z_dimension))\n",
    "    prefix[np.arange(batch_size), label] = 1\n",
    "    z = np.random.normal(0, .3, (batch_size, z_dimension))\n",
    "#     prefix = prefix / np.linalg.norm(prefix)\n",
    "#     z = z + prefix\n",
    "    z[np.where(prefix.astype(int))] = 1\n",
    "    return torch.from_numpy(z).float().view(-1, z_dimension, 1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Discriminator, self).__init__() # b d 32 32\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, d, 4, 2, 2) # d 15 15 \n",
    "        self.conv2 = nn.Conv2d(d, d*2, 4, 2, 2) # d*2 8 8\n",
    "        self.conv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1) # d*4 4 4\n",
    "        self.conv3_bn = nn.BatchNorm2d(d*4)\n",
    "        self.conv4 = nn.Conv2d(d*4, 1, 4, 2, 1) # 1 1 1\n",
    "        \n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv2d(d*8, 1, 4, 1, 0),\n",
    "#             nn.Sigmoid()\n",
    "#         ) # b 1 7 7\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d * 4 * 4 * 4, 10),\n",
    "#             nn.LeakyReLU(.2, True),\n",
    "#             nn.Linear(1024, 10),\n",
    "            nn.Sigmoid(),\n",
    "        ) # b 10\n",
    "        \n",
    "\n",
    "    \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 1 32 32\n",
    "        outs = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        outs = F.leaky_relu(self.conv2_bn(self.conv2(outs)), 0.2)\n",
    "        outs = F.leaky_relu(self.conv3_bn(self.conv3(outs)), 0.2)\n",
    "\n",
    "        img = torch.sigmoid(self.conv4(outs)) # F.sigmoid\n",
    "        \n",
    "#         print(outs.view(x.size(0), -1).shape)\n",
    "#         outs = F.sigmoid(self.conv5(outs))\n",
    "#         img = F.sigmoid(outs)\n",
    "        con = self.fc(outs.view(x.size(0), -1))\n",
    "        \n",
    "        return img, con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, d=128):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "#         self.deconv1 = nn.ConvTranspose2d(z_dimension, d*8, 4, 1, 0) # b d*8 4 4\n",
    "#         self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
    "#         self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1) # b d*4 8 8\n",
    "#         self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
    "#         self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1) # b d*2 16 16\n",
    "#         self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
    "#         self.deconv4 = nn.ConvTranspose2d(d*2, d, 4, 2, 1) # b d 32 32\n",
    "#         self.deconv4_bn = nn.BatchNorm2d(d)\n",
    "#         self.deconv5 = nn.ConvTranspose2d(d, 1, 4, 2, 1) # b 1 64 64\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose2d(z_dimension, d*4, 1, 1, 0) # b d*8 1 1\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d*4)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d*4, d*2, 8, 2, 0) # b d*2 8 8\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d*2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d*2, d, 4, 2, 1) # b d 16 16\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d, 1, 4, 2, 1) # b 1 32 32\n",
    "    \n",
    "        \n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "            \n",
    "    def forward(self, x): # b 100 28 28\n",
    "        outs = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
    "        outs = F.relu(self.deconv2_bn(self.deconv2(outs)))\n",
    "        outs = F.relu(self.deconv3_bn(self.deconv3(outs)))\n",
    "        outs = torch.tanh(self.deconv4(outs))\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Discriminator(128).to(device)\n",
    "G = Generator(128).to(device)\n",
    "\n",
    "# D.weight_init(.0, 0.02)\n",
    "# G.weight_init(.0, 0.02)\n",
    "\n",
    "D = nn.DataParallel(D, device_ids=device_ids).to(device)\n",
    "G = nn.DataParallel(G, device_ids=device_ids).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "d_optimezer = optim.Adam(D.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "g_optimezer = optim.Adam(G.parameters(), lr=2e-4, betas=(0, 0.9))\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "one = one.to(device)\n",
    "mone = mone.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(os.path.join('./log/cnn_cwdcgan_gp', str(now)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(\"save_images/cnn_cwdcgan_gp\", str(now))\n",
    "if not os.path.exists(img_path): os.makedirs(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label = np.arange(10)\n",
    "condition_noise = gen_noise(10, condition_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e7384dbdde4d94951ac9fd075aae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch[1/30], Step:  38400, d_loss: 2.118618, g_loss: 1.252115\n",
      "    real_scores: 0.396415, fake_scores: 0.511313, W: 0.114898\n",
      "Finish Epoch [1/30], D Loss: 301.523165, G Loss: 142.414917\n",
      "  Epoch[2/30], Step:  38400, d_loss: 1.518741, g_loss: 1.175065\n",
      "    real_scores: 0.678788, fake_scores: 0.578850, W: -0.099938\n",
      "Finish Epoch [2/30], D Loss: 102.323787, G Loss: 64.362875\n",
      "  Epoch[3/30], Step:  38400, d_loss: 1.679481, g_loss: 0.989488\n",
      "    real_scores: 0.659622, fake_scores: 0.577782, W: -0.081840\n",
      "Finish Epoch [3/30], D Loss: 64.931830, G Loss: 44.708702\n",
      "  Epoch[4/30], Step:  38400, d_loss: 1.170661, g_loss: 1.127864\n",
      "    real_scores: 0.689496, fake_scores: 0.363497, W: -0.325998\n",
      "Finish Epoch [4/30], D Loss: 45.612027, G Loss: 33.966598\n",
      "  Epoch[5/30], Step:  38400, d_loss: 1.247106, g_loss: 1.171078\n",
      "    real_scores: 0.701166, fake_scores: 0.440933, W: -0.260233\n",
      "Finish Epoch [5/30], D Loss: 36.096847, G Loss: 27.407148\n",
      "  Epoch[6/30], Step:  38400, d_loss: 1.245697, g_loss: 1.059310\n",
      "    real_scores: 0.624514, fake_scores: 0.369555, W: -0.254959\n",
      "Finish Epoch [6/30], D Loss: 29.433899, G Loss: 23.352364\n",
      "  Epoch[7/30], Step:  38400, d_loss: 1.299741, g_loss: 1.014136\n",
      "    real_scores: 0.608716, fake_scores: 0.387643, W: -0.221073\n",
      "Finish Epoch [7/30], D Loss: 25.605463, G Loss: 19.460231\n",
      "  Epoch[8/30], Step:  38400, d_loss: 1.336302, g_loss: 1.116821\n",
      "    real_scores: 0.674875, fake_scores: 0.454389, W: -0.220486\n",
      "Finish Epoch [8/30], D Loss: 22.353320, G Loss: 17.278092\n",
      "  Epoch[9/30], Step:  38400, d_loss: 2.817695, g_loss: 1.338564\n",
      "    real_scores: 0.529977, fake_scores: 0.296307, W: -0.233670\n",
      "Finish Epoch [9/30], D Loss: 20.067441, G Loss: 15.186700\n",
      "  Epoch[10/30], Step:  38400, d_loss: 1.296071, g_loss: 1.143314\n",
      "    real_scores: 0.692699, fake_scores: 0.489493, W: -0.203207\n",
      "Finish Epoch [10/30], D Loss: 17.927578, G Loss: 13.522580\n",
      "  Epoch[11/30], Step:  38400, d_loss: 1.764169, g_loss: 1.371996\n",
      "    real_scores: 0.626486, fake_scores: 0.441046, W: -0.185440\n",
      "Finish Epoch [11/30], D Loss: 16.462262, G Loss: 12.363900\n",
      "  Epoch[12/30], Step:  38400, d_loss: 1.474276, g_loss: 1.127590\n",
      "    real_scores: 0.374067, fake_scores: 0.346379, W: -0.027688\n",
      "Finish Epoch [12/30], D Loss: 15.088497, G Loss: 11.343590\n",
      "  Epoch[13/30], Step:  38400, d_loss: 1.393565, g_loss: 1.129407\n",
      "    real_scores: 0.433761, fake_scores: 0.345389, W: -0.088371\n",
      "Finish Epoch [13/30], D Loss: 13.897741, G Loss: 10.437909\n",
      "  Epoch[14/30], Step:  38400, d_loss: 1.291649, g_loss: 1.128846\n",
      "    real_scores: 0.533177, fake_scores: 0.341746, W: -0.191432\n",
      "Finish Epoch [14/30], D Loss: 12.952691, G Loss: 10.027900\n",
      "  Epoch[15/30], Step:  38400, d_loss: 1.315527, g_loss: 1.111956\n",
      "    real_scores: 0.523040, fake_scores: 0.362168, W: -0.160873\n",
      "Finish Epoch [15/30], D Loss: 12.128048, G Loss: 9.511641\n",
      "  Epoch[16/30], Step:  38400, d_loss: 1.358587, g_loss: 1.104148\n",
      "    real_scores: 0.504797, fake_scores: 0.384908, W: -0.119890\n",
      "Finish Epoch [16/30], D Loss: 11.389954, G Loss: 8.881523\n",
      "  Epoch[17/30], Step:  38400, d_loss: 1.633592, g_loss: 1.352889\n",
      "    real_scores: 0.734352, fake_scores: 0.480211, W: -0.254141\n",
      "Finish Epoch [17/30], D Loss: 10.649825, G Loss: 8.411361\n",
      "  Epoch[18/30], Step:  38400, d_loss: 1.363787, g_loss: 1.073054\n",
      "    real_scores: 0.496368, fake_scores: 0.365564, W: -0.130804\n",
      "Finish Epoch [18/30], D Loss: 10.124186, G Loss: 7.987694\n",
      "  Epoch[19/30], Step:  38400, d_loss: 1.325861, g_loss: 1.139827\n",
      "    real_scores: 0.402236, fake_scores: 0.217153, W: -0.185083\n",
      "Finish Epoch [19/30], D Loss: 9.592889, G Loss: 7.698007\n",
      "  Epoch[20/30], Step:  38400, d_loss: 1.417962, g_loss: 0.963105\n",
      "    real_scores: 0.504798, fake_scores: 0.346691, W: -0.158107\n",
      "Finish Epoch [20/30], D Loss: 9.089134, G Loss: 7.274405\n",
      "  Epoch[21/30], Step:  38400, d_loss: 1.473669, g_loss: 1.281061\n",
      "    real_scores: 0.193795, fake_scores: 0.188894, W: -0.004901\n",
      "Finish Epoch [21/30], D Loss: 8.692129, G Loss: 6.869856\n",
      "  Epoch[22/30], Step:  38400, d_loss: 1.449367, g_loss: 1.198608\n",
      "    real_scores: 0.303549, fake_scores: 0.279746, W: -0.023803\n",
      "Finish Epoch [22/30], D Loss: 8.235548, G Loss: 6.532912\n",
      "  Epoch[23/30], Step:  38400, d_loss: 1.368510, g_loss: 1.122297\n",
      "    real_scores: 0.496849, fake_scores: 0.374490, W: -0.122359\n",
      "Finish Epoch [23/30], D Loss: 8.045460, G Loss: 6.394203\n",
      "  Epoch[24/30], Step:  38400, d_loss: 1.375831, g_loss: 1.106543\n",
      "    real_scores: 0.443672, fake_scores: 0.334325, W: -0.109347\n",
      "Finish Epoch [24/30], D Loss: 7.724760, G Loss: 6.066966\n",
      "  Epoch[25/30], Step:  38400, d_loss: 1.306448, g_loss: 1.123955\n",
      "    real_scores: 0.468714, fake_scores: 0.302714, W: -0.166001\n",
      "Finish Epoch [25/30], D Loss: 7.191478, G Loss: 5.761197\n",
      "  Epoch[26/30], Step:  38400, d_loss: 1.338080, g_loss: 1.111513\n",
      "    real_scores: 0.515548, fake_scores: 0.380418, W: -0.135130\n",
      "Finish Epoch [26/30], D Loss: 7.043898, G Loss: 5.601506\n",
      "  Epoch[27/30], Step:  38400, d_loss: 1.421959, g_loss: 0.944804\n",
      "    real_scores: 0.608917, fake_scores: 0.543206, W: -0.065710\n",
      "Finish Epoch [27/30], D Loss: 6.962957, G Loss: 5.308114\n",
      "  Epoch[28/30], Step:  38400, d_loss: 1.365094, g_loss: 1.103955\n",
      "    real_scores: 0.459489, fake_scores: 0.354619, W: -0.104870\n",
      "Finish Epoch [28/30], D Loss: 6.845401, G Loss: 5.181412\n",
      "  Epoch[29/30], Step:  38400, d_loss: 1.382543, g_loss: 1.222559\n",
      "    real_scores: 0.496270, fake_scores: 0.367318, W: -0.128952\n",
      "Finish Epoch [29/30], D Loss: 6.333978, G Loss: 4.942659\n",
      "  Epoch[30/30], Step:  38400, d_loss: 1.451741, g_loss: 1.204326\n",
      "    real_scores: 0.294221, fake_scores: 0.254100, W: -0.040121\n",
      "Finish Epoch [30/30], D Loss: 6.153956, G Loss: 4.987005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = len(dataloader)\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    _step = epoch * total_count\n",
    "    \n",
    "    d_loss_total = .0\n",
    "    g_loss_total = .0\n",
    "    for i, (img, lab) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        ########## D ##########\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad_(True)\n",
    "            \n",
    "        label = gen_noise_label(img.size(0))\n",
    "        z = gen_noise(img.size(0), label)\n",
    "#         with torch.no_grad():\n",
    "#             zz = z\n",
    "        fake_img = G(z).detach() ###\n",
    "        \n",
    "        real_img = img.cuda()\n",
    "        real_lab = lab.cuda()\n",
    "        real_out, real_label = D(real_img)\n",
    "        real_lab_loss = criterion(real_label, real_lab)\n",
    "        d_loss_real_lab = real_lab_loss.mean()\n",
    "        d_loss_real = real_out.mean()\n",
    "        real_scores = real_out\n",
    "        \n",
    "        fake_img = G(z).detach()\n",
    "        fake_out, fake_label = D(fake_img)\n",
    "        d_loss_fake = fake_out.mean()\n",
    "        fake_scores = fake_out\n",
    "        \n",
    "        gradient_penalty = calc_gradient_penalty(D, real_img, fake_img)\n",
    "        \n",
    "        d_loss = d_loss_fake - d_loss_real + gradient_penalty + 1 * d_loss_real_lab\n",
    "        \n",
    "        d_optimezer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimezer.step()\n",
    "        \n",
    "        #######################\n",
    "        w_dist = d_loss_fake - d_loss_real\n",
    "        \n",
    "        \n",
    "        ########## G ##########\n",
    "        for p in D.parameters():\n",
    "            p.requires_grad_(False)\n",
    "        \n",
    "        label = gen_noise_label(img.size(0))\n",
    "        z = gen_noise(img.size(0), label)\n",
    "        fake_img = G(z)\n",
    "        fake_out, fake_label = D(fake_img)\n",
    "\n",
    "        gen_label = torch.from_numpy(label).long().to(device)\n",
    "        gen_label_loss = criterion(fake_label, gen_label).mean()\n",
    "        gen_cost = -fake_out.mean()\n",
    "        g_loss = 1 * gen_label_loss + gen_cost\n",
    "\n",
    "        g_optimezer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimezer.step()\n",
    "        \n",
    "        #######################\n",
    "        \n",
    "        d_loss_total += d_loss.item() * img.size(0)\n",
    "        g_loss_total += g_loss.item() * img.size(0)\n",
    "        \n",
    "        step = _step + i + 1\n",
    "        \n",
    "        if (i + 1) % 100 == 0:\n",
    "            writer.add_scalar('Discriminator Real Loss', d_loss_real.item(), step)\n",
    "            writer.add_scalar('Discriminator Fake Loss', d_loss_fake.item(), step)\n",
    "            writer.add_scalar('Discriminator Loss', d_loss.item(), step)\n",
    "            writer.add_scalar('Generator Loss', g_loss.item(), step)\n",
    "            writer.add_scalar('Wasserstein Distance', w_dist.item(), step)\n",
    "        \n",
    "        \n",
    "        if (i + 1) % 300 == 0:\n",
    "            tqdm.write('Epoch[{}/{}], Step: {:6d}, d_loss: {:.6f}, g_loss: {:.6f}\\n    real_scores: {:.6f}' \\\n",
    "', fake_scores: {:.6f}, W: {:.6f}'.format(epoch+1, num_epochs, \n",
    "                                          (i+1) * BATCH_SIZE, \n",
    "                                          d_loss, g_loss, \n",
    "                                          real_scores.mean(), \n",
    "                                          fake_scores.mean(), w_dist))\n",
    "    \n",
    "    \n",
    "    setp = (epoch + 1) * total_count\n",
    "    _d_loss_total = d_loss_total / (total_count * (epoch + 1))\n",
    "    _g_loss_total = g_loss_total / (total_count * (epoch + 1))\n",
    "    \n",
    "    writer.add_scalar('Discriminator Total Loss', _d_loss_total, step)\n",
    "    writer.add_scalar('Generator Total Loss', _g_loss_total, step)\n",
    "    \n",
    "    tqdm.write(\"Finish Epoch [{}/{}], D Loss: {:.6f}, G Loss: {:.6f}\".format(epoch+1, \n",
    "                                                                             num_epochs, \n",
    "                                                                             _d_loss_total,\n",
    "                                                                             _g_loss_total, ))\n",
    "    \n",
    "    writer.add_image('Generator Image', make_grid(fake_img.view(-1, 1, 32, 32).cpu().data, normalize=True, scale_each=True), step)\n",
    "    condition_img = G(condition_noise).view(-1, 1, 32, 32).cpu().data\n",
    "    writer.add_image('Condition Generator Image', make_grid(condition_img, normalize=True, scale_each=True), step)\n",
    "    save_image(condition_img, os.path.join(img_path, 'condition_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    if epoch == 0:\n",
    "        real_images = real_img.view(-1, 1, 32, 32).cpu().data\n",
    "        save_image(real_images, os.path.join(img_path, 'real_images.png'))\n",
    "    \n",
    "    fake_images = fake_img.view(-1, 1, 32, 32).cpu().data\n",
    "    save_image(fake_images, os.path.join(img_path, 'fake_images-{}.png'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(D.state_dict(), './ser/cnn_cwdcgan_gp_discriminator.pt')\n",
    "torch.save(G.state_dict(), './ser/cnn_cwdcgan_gp_generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 7 0 7 5 8 8 4 8 2 1 1 3 2 4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clabel = np.array([4,5,3,8,0])\n",
    "clabel = np.random.randint(0, 10, 16)\n",
    "print(clabel)\n",
    "z = gen_noise(clabel.shape[0], clabel)\n",
    "\n",
    "images = G(z)\n",
    "# save_image(images, 'xx.png')\n",
    "plt.imshow(Image.fromarray(make_grid(images).mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()))\n",
    "# plt.imshow(make_grid(condition_img, normalize=True, scale_each=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "556px",
    "left": "247px",
    "right": "398px",
    "top": "131px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
